import { join } from '@std/path';
import { ensureDir } from '@std/fs';
import type { JSX } from 'preact';
import { renderToString } from 'preact-render-to-string';

import LogEntryFormatterManager from '../logEntries/logEntryFormatterManager.ts';
import type ProjectEditor from 'api/editor/projectEditor.ts';
import type {
	CollaborationId,
	CollaborationLogDataEntry,
	InteractionId,
	InteractionStats,
	ProjectId,
	TokenUsageStatsForCollaboration,
} from 'shared/types.ts';
import { DEFAULT_TOKEN_USAGE_REQUIRED } from 'shared/types.ts';
import type { AuxiliaryChatContent } from 'api/logEntries/types.ts';
import type { LLMModelConfig } from 'api/types/llms.ts';
import { getProjectAdminDataDir } from 'shared/projectPath.ts';
import { logger } from 'shared/logger.ts';
import { getConfigManager } from 'shared/config/configManager.ts';
//import { ThinkingExtractor } from '../utils/thinkingExtractor.ts';
import type {
	LLMToolFormatterDestination,
	LLMToolInputSchema,
	LLMToolRunBbResponse,
	LLMToolRunResultContent,
} from 'api/llms/llmTool.ts';

export type CollaborationLogEntryType =
	| 'user'
	| 'orchestrator' // user role, but prompt generated by LLM
	| 'assistant'
	| 'tool_use'
	| 'tool_result'
	| 'answer'
	| 'auxiliary'
	| 'error'; //text_change

export interface CollaborationLogEntryContentToolResult {
	toolResult: LLMToolRunResultContent;
	bbResponse: LLMToolRunBbResponse;
}

export type CollaborationLogEntryContent =
	| string
	| AuxiliaryChatContent
	| LLMToolInputSchema
	| CollaborationLogEntryContentToolResult;

export interface CollaborationLogEntry {
	entryType: CollaborationLogEntryType;
	content: CollaborationLogEntryContent;
	thinking?: string;
	toolName?: string;
}

const configManager = await getConfigManager();
const globalConfig = await configManager.getGlobalConfig();

export default class CollaborationLogger {
	private logFileRaw!: string;
	private logFileJson!: string;
	private collaborationLogsDir!: string;
	private ensuredDir: boolean = false;
	private static readonly ENTRY_SEPARATOR = '<<<BB_LOG_ENTRY_SEPARATOR>>>';
	private entryTypeLabels: Record<
		CollaborationLogEntryType,
		string
	> = {
		user: globalConfig.myPersonsName || 'Person',
		orchestrator: `${globalConfig.myAssistantsName || 'Assistant'} as Orchestrator`,
		assistant: globalConfig.myAssistantsName || 'Assistant',
		answer: `Answer from ${globalConfig.myAssistantsName || 'Assistant'}`,
		tool_use: 'Tool Input',
		tool_result: 'Tool Output',
		auxiliary: 'Auxiliary Chat',
		error: 'Error',
	};
	private logEntryFormatterManager!: LogEntryFormatterManager;
	private projectId: ProjectId;

	constructor(
		private projectEditor: ProjectEditor,
		private collaborationId: CollaborationId,
		private logEntryHandler: (
			messageId: string,
			parentMessageId: string | null,
			collaborationId: CollaborationId,
			//parentInteractionId: InteractionId,
			agentInteractionId: InteractionId | null,
			timestamp: string,
			logEntry: CollaborationLogEntry,
			interactionStats: InteractionStats,
			tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
			modelConfig?: LLMModelConfig,
		) => Promise<void>,
	) {
		this.projectId = projectEditor.projectId;
	}

	async init(): Promise<CollaborationLogger> {
		this.logEntryFormatterManager = await new LogEntryFormatterManager(this.projectEditor).init();

		this.collaborationLogsDir = await CollaborationLogger.getLogFileDirPath(this.projectId, this.collaborationId);

		this.logFileRaw = await CollaborationLogger.getLogFileRawPath(this.projectId, this.collaborationId);
		this.logFileJson = await CollaborationLogger.getLogFileJsonPath(this.projectId, this.collaborationId);

		const projectConfig = await configManager.getProjectConfig(this.projectId);
		this.entryTypeLabels.user = projectConfig.myPersonsName || 'Person';
		this.entryTypeLabels.orchestrator = `${projectConfig.myAssistantsName || 'Assistant'} as Orchestrator`;
		this.entryTypeLabels.assistant = projectConfig.myAssistantsName || 'Assistant';
		this.entryTypeLabels.answer = `Answer from ${projectConfig.myAssistantsName || 'Assistant'}`;

		return this;
	}

	async ensureCollaborationLogsDir(): Promise<void> {
		if (this.ensuredDir) return;
		await ensureDir(this.collaborationLogsDir);
		this.ensuredDir = true;
	}
	static async getLogFileDirPath(projectId: ProjectId, collaborationId: string): Promise<string> {
		const projectAdminDir = await getProjectAdminDataDir(projectId);
		const collaborationLogsDir = join(projectAdminDir, 'collaborations', collaborationId);
		//await ensureDir(collaborationLogsDir);
		return collaborationLogsDir;
	}
	static async getLogFileRawPath(projectId: ProjectId, collaborationId: string): Promise<string> {
		const collaborationLogsDir = await CollaborationLogger.getLogFileDirPath(projectId, collaborationId);
		return join(collaborationLogsDir, 'collaboration.log');
	}
	static async getLogFileJsonPath(projectId: ProjectId, collaborationId: string): Promise<string> {
		const collaborationLogsDir = await CollaborationLogger.getLogFileDirPath(projectId, collaborationId);
		return join(collaborationLogsDir, 'collaboration.jsonl');
	}

	static async getLogDataEntries(
		projectId: ProjectId,
		collaborationId: string,
	): Promise<Array<CollaborationLogDataEntry>> {
		const collaborationLogFile = await CollaborationLogger.getLogFileJsonPath(projectId, collaborationId);
		const content = await Deno.readTextFile(collaborationLogFile);
		return content.trim().split('\n').map((line) => JSON.parse(line));
	}

	private async appendToRawLog(content: string) {
		await this.ensureCollaborationLogsDir();
		await Deno.writeTextFile(this.logFileRaw, content + '\n', { append: true });
	}
	private async appendToJsonLog(content: string) {
		await this.ensureCollaborationLogsDir();
		await Deno.writeTextFile(this.logFileJson, content + '\n', { append: true });
	}

	private getTimestamp(): string {
		return new Date().toISOString();
	}

	private async logEntry(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		logEntry: CollaborationLogEntry,
		interactionStats: InteractionStats = { statementCount: 0, statementTurnCount: 0, interactionTurnCount: 0 },
		tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration = {
			tokenUsageTurn: DEFAULT_TOKEN_USAGE_REQUIRED(),
			tokenUsageStatement: DEFAULT_TOKEN_USAGE_REQUIRED(),
			tokenUsageInteraction: DEFAULT_TOKEN_USAGE_REQUIRED(),
			tokenUsageCollaboration: DEFAULT_TOKEN_USAGE_REQUIRED(),
		},
		modelConfig?: LLMModelConfig,
	) {
		const timestamp = this.getTimestamp();

		// logEntryHandler handles emitting events for cli and bui
		try {
			await this.logEntryHandler(
				messageId,
				parentMessageId,
				this.collaborationId,
				//parentInteractionId,
				agentInteractionId,
				timestamp,
				logEntry,
				interactionStats,
				tokenUsageStatsForCollaboration,
				modelConfig,
			);
		} catch (error) {
			logger.error('Error in logEntryHandler:', error);
		}

		const rawEntry = await this.createRawEntryWithSeparator(
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			timestamp,
			logEntry,
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		);
		try {
			await this.appendToRawLog(rawEntry);
		} catch (error) {
			logger.error('Error appending to raw log:', error);
		}

		const jsonEntry = JSON.stringify({
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			timestamp,
			logEntry,
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		});
		try {
			await this.appendToJsonLog(jsonEntry);
		} catch (error) {
			logger.error('Error appending to json log:', error as Error);
		}
	}

	async logUserMessage(
		messageId: string,
		message: string,
		interactionStats: InteractionStats,
	) {
		await this.logEntry(messageId, null, null, { entryType: 'user', content: message }, interactionStats);
	}

	async logOrchestratorMessage(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		message: string,
		interactionStats: InteractionStats,
	) {
		await this.logEntry(
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			{ entryType: 'orchestrator', content: message },
			interactionStats,
		);
	}

	async logAssistantMessage(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		message: string,
		thinking: string,
		interactionStats: InteractionStats,
		tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
		modelConfig?: LLMModelConfig,
	) {
		await this.logEntry(
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			{
				entryType: 'assistant',
				content: message,
				thinking: thinking,
			},
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		);
	}

	async logAnswerMessage(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		answer: string,
		assistantThinking: string,
		interactionStats: InteractionStats,
		tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
		modelConfig?: LLMModelConfig,
	) {
		await this.logEntry(
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			{
				entryType: 'answer',
				content: answer,
				thinking: assistantThinking,
			},
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		);
	}

	async logAuxiliaryMessage(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		message: string | AuxiliaryChatContent,
		interactionStats?: InteractionStats,
		tokenUsageStatsForCollaboration?: TokenUsageStatsForCollaboration,
		modelConfig?: LLMModelConfig,
	) {
		await this.logEntry(
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			{ entryType: 'auxiliary', content: message },
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		);
	}

	async logToolUse(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		toolName: string,
		toolInput: LLMToolInputSchema,
		interactionStats: InteractionStats,
		tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
		modelConfig?: LLMModelConfig,
	) {
		try {
			await this.logEntry(
				messageId,
				parentMessageId,
				//parentInteractionId,
				agentInteractionId,
				{ entryType: 'tool_use', content: toolInput, toolName },
				interactionStats,
				tokenUsageStatsForCollaboration,
				modelConfig,
			);
		} catch (error) {
			logger.error('Error in logEntry for logToolUse:', error);
		}
	}

	async logToolResult(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		toolName: string,
		toolResult: LLMToolRunResultContent,
		bbResponse: LLMToolRunBbResponse,
	) {
		try {
			await this.logEntry(
				messageId,
				parentMessageId,
				//parentInteractionId,
				agentInteractionId,
				{
					entryType: 'tool_result',
					content: { toolResult, bbResponse },
					toolName,
				},
			);
		} catch (error) {
			logger.error('Error in logEntry for logToolResult:', error);
		}
	}

	async logError(
		messageId: string,
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		error: string,
	) {
		await this.logEntry(
			messageId,
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			{
				entryType: 'error',
				content: error,
			},
		);
	}

	//async logTextChange(filePath: string, change: string) {
	//	const message = `Diff Patch for ${filePath}:\n${change}`;
	//	await this.logEntry('text_change', message);
	//}

	async createRawEntry(
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		timestamp: string,
		logEntry: CollaborationLogEntry,
		_interactionStats: InteractionStats,
		_tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
		_modelConfig?: LLMModelConfig,
	): Promise<string> {
		// [TODO] add token usage to header line
		const formattedContent = await this.logEntryFormatterManager.formatLogEntry(
			'console' as LLMToolFormatterDestination, // [TODO] we need a 'file' destination, use 'console' with ansi stripped
			logEntry,
			{}, // options
		);

		// Convert JSX to HTML string if necessary
		const rawEntryContent = typeof formattedContent === 'string'
			? formattedContent
			: renderToString(formattedContent.content as JSX.Element);

		const label = this.entryTypeLabels[logEntry.entryType] || 'Unknown';
		return `## ${label} [${timestamp}] [CollaborationId: ${this.collaborationId || '--'}][AgentId: ${
			agentInteractionId || '--'
		}][Parent MessageId:${parentMessageId || '--'}]\n${rawEntryContent.trim()}`;
	}

	async createRawEntryWithSeparator(
		parentMessageId: string | null,
		//parentInteractionId: InteractionId | null,
		agentInteractionId: InteractionId | null,
		timestamp: string,
		logEntry: CollaborationLogEntry,
		interactionStats: InteractionStats,
		tokenUsageStatsForCollaboration: TokenUsageStatsForCollaboration,
		modelConfig?: LLMModelConfig,
	): Promise<string> {
		let rawEntry = await this.createRawEntry(
			parentMessageId,
			//parentInteractionId,
			agentInteractionId,
			timestamp,
			logEntry,
			interactionStats,
			tokenUsageStatsForCollaboration,
			modelConfig,
		);
		// Ensure entry ends with a single newline and the separator
		rawEntry = rawEntry.trimEnd() + '\n' + CollaborationLogger.getEntrySeparator() + '\n';
		return rawEntry;
	}

	static getEntrySeparator(): string {
		return this.ENTRY_SEPARATOR.trim();
	}
}
